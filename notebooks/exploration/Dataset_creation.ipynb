{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1fTt3FcWCkgxR8Tezfp8YhCgFz8O4IfAl","authorship_tag":"ABX9TyPLS/GWHYsffRFrbubHL7Bz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":121,"metadata":{"id":"kD53VEaCmRlW","executionInfo":{"status":"ok","timestamp":1682515660640,"user_tz":-120,"elapsed":262,"user":{"displayName":"Nico Grassetto","userId":"05768056407247944692"}}},"outputs":[],"source":["from torch.utils.data import Dataset\n","import pathlib\n","import os\n","from PIL import Image\n","import numpy as np\n","\n","class HMDB51Dataset():\n","  def __init__(self, targ_dir: str, transform=None):\n","    self.total_examples = self.count_subfolders(targ_dir)\n","    self.classes, self.class_to_index = self.get_classes(targ_dir)\n","    self.paths = self.get_paths(targ_dir)\n","\n","  def __len__(self):\n","    return self.total_examples\n","\n","  def __getitem__(self, index: int):\n","    X = self.get_example(self.paths[index])\n","    y = self.get_label(self.paths[index])\n","    return X, y\n","\n","  def count_subfolders(self, folder_path):\n","      count = 0\n","      for folder in os.listdir(folder_path):\n","          subfolder_path = os.path.join(folder_path, folder)\n","          if os.path.isdir(subfolder_path):\n","              for subfolder in os.listdir(subfolder_path):\n","                  if os.path.isdir(os.path.join(subfolder_path, subfolder)):\n","                      count += 1\n","      return count\n","\n","  def get_classes(self, targ_dir: str):\n","\n","      count = 0\n","      classes = []\n","      indexes = []\n","\n","      for folder in os.listdir(targ_dir):\n","          subfolder_path = os.path.join(targ_dir, folder)\n","          classes.append(folder)\n","          indexes.append(count)\n","          count += 1\n","      return classes, indexes\n","\n","  def get_paths(self, targ_dir: str):\n","    path_obj = pathlib.Path(targ_dir)\n","    paths = []\n","\n","    for subfolder in path_obj.iterdir():\n","        if subfolder.is_dir():      \n","            for subsubfolder in subfolder.iterdir():\n","                if subsubfolder.is_dir():\n","                    paths.append(subsubfolder.resolve().as_posix())\n","    return paths\n","  \n","  def get_label(self, directory: str):\n","    return self.classes.index(pathlib.Path(directory).parts[-2])\n","\n","  def get_example(self, directory: str):\n","    segments = []\n","    segment_prefix = \"/segment-\"\n","    FLOW_FRAME_NAME = \"flow_frame.png\"\n","    RGB_FRAME_NAME = \"rgb_frame.png\"\n","    POSE_FRAME_NAME = \"pose_frame.png\"\n","    SEGMENTS_NUMBER = self.get_subfolders_number(directory)\n","    \n","    for segment_index in range(SEGMENTS_NUMBER):\n","      segment_path = directory + segment_prefix + str(segment_index) + \"/\"\n","      rgb_frame_path = segment_path + RGB_FRAME_NAME\n","      flow_frame_path = segment_path + FLOW_FRAME_NAME\n","      pose_frame_path = segment_path + POSE_FRAME_NAME\n","      \n","      # Let's get the actual images\n","      rgb_frame = np.asarray(Image.open(rgb_frame_path))\n","      print(f\"rgb frame dimensions: {rgb_frame.shape}\")\n","      # flow_frame = np.asarray(Image.open(flow_frame_path))\n","      # print(f\"flow frame dimensions: {flow_frame.shape}\")\n","      # pose_frame = np.asarray(Image.open(pose_frame_path))\n","      # print(f\"pose frame dimensions: {pose_frame.shape}\")\n","      \n","      segments.append((rgb_frame))#prev flow_frame, pose_frame\n","\n","    return segments\n","  def get_subfolders_number(self, directory):\n","    path_obj = pathlib.Path(directory)\n","\n","    num_subfolders = 0\n","    for subfolder in path_obj.iterdir():\n","        if subfolder.is_dir():\n","            num_subfolders += 1\n","    return num_subfolders"]},{"cell_type":"code","source":["dataset = HMDB51Dataset(\"/content/drive/MyDrive/thesis/data/HMDB-51-downsampled_copy\")"],"metadata":{"id":"of4TD8h6axYc","executionInfo":{"status":"ok","timestamp":1682515663091,"user_tz":-120,"elapsed":673,"user":{"displayName":"Nico Grassetto","userId":"05768056407247944692"}}},"execution_count":122,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader \n","\n","dataloader = DataLoader(dataset=dataset, batch_size=2, num_workers=2, shuffle=True)"],"metadata":{"id":"6v7pGER4rgZP","executionInfo":{"status":"ok","timestamp":1682515663092,"user_tz":-120,"elapsed":3,"user":{"displayName":"Nico Grassetto","userId":"05768056407247944692"}}},"execution_count":123,"outputs":[]},{"cell_type":"code","source":["video_batch, label_batch = next(iter(dataloader))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":948},"id":"1ygoMHjusODN","executionInfo":{"status":"error","timestamp":1682515664392,"user_tz":-120,"elapsed":938,"user":{"displayName":"Nico Grassetto","userId":"05768056407247944692"}},"outputId":"98ed34ea-f4e7-4289-b393-bf653df9b32c"},"execution_count":124,"outputs":[{"output_type":"stream","name":"stdout","text":["rgb frame dimensions: (240, 320, 3)\n","rgb frame dimensions: (240, 320, 3)\n","rgb frame dimensions: (240, 320, 3)\n","rgb frame dimensions: (240, 432, 3)\n","rgb frame dimensions: (240, 432, 3)\n","rgb frame dimensions: (240, 432, 3)\n","rgb frame dimensions: (240, 416, 3)\n","rgb frame dimensions: (240, 416, 3)\n","rgb frame dimensions: (240, 416, 3)\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-124-bdc1cec77043>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvideo_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 264, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 145, in collate\n    return elem_type([collate(samples, collate_fn_map=collate_fn_map) for samples in transposed])\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 145, in <listcomp>\n    return elem_type([collate(samples, collate_fn_map=collate_fn_map) for samples in transposed])\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 171, in collate_numpy_array_fn\n    return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [240, 320, 3] at entry 0 and [240, 432, 3] at entry 1\n"]},{"output_type":"stream","name":"stdout","text":["rgb frame dimensions: (240, 416, 3)\n"]}]},{"cell_type":"code","source":["len(video_batch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hm8ydvkJu4JQ","executionInfo":{"status":"ok","timestamp":1682515417959,"user_tz":-120,"elapsed":446,"user":{"displayName":"Nico Grassetto","userId":"05768056407247944692"}},"outputId":"f6607ef9-e667-491d-dc17-ff74a3f41e4c"},"execution_count":114,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":114}]}]}